{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb3ad60c",
   "metadata": {},
   "source": [
    "# Mini Challenge DLBS Oliver - Fabian\n",
    "## Zuverlässige Lokalisierung von Hunden in Überwachungs- und Alltagsaufnahmen\n",
    " \n",
    "Im Rahmen dieser Untersuchung steht die präzise und robuste Lokalisierung von **Hunden** im Vordergrund, wobei Bilddaten aus **Überwachungskameras** (sowohl Indoor als auch Outdoor) und **„normalen“ Fotoaufnahmen** herangezogen werden. Ziel ist es, ein auf Hunde spezialisiertes Convolutional Neural Network (CNN) zu trainieren und systematisch zu evaluieren, wie zuverlässig es Hunde in unterschiedlich komplexen und realistischen Szenarien erkennen und lokalisieren kann.  \n",
    " \n",
    "## 1. Eingrenzung des Anwendungsbereichs  \n",
    "Wir fokussieren uns ausschliesslich auf die Klasse **Hund** und betrachten keine weiteren Heimtiere wie Katzen oder Kleintiere. Untersucht werden zwei Hauptquellen für Bilddaten:  \n",
    "- **Überwachungskameras**: stationäre Video- oder Fotokameras, installiert in Innen- (z. B. Flure, Wohnzimmer) und Aussenbereichen (z. B. Hof, Garten).  \n",
    "- **Normale Fotoaufnahmen**: manuell oder automatisch erstellte Bilder, welche Hunde frontal, seitlich oder von hinten zeigen, sowohl in Innenräumen als auch unter freiem Himmel.  \n",
    " \n",
    "## 2. Vielfalt der Aufnahmeszenarien  \n",
    "Um ein breites Spektrum typischer Anwendungssituationen abzudecken, werden folgende Aufnahmetypen in den Datensatz aufgenommen:  \n",
    "1. **Überwachungskameras – Indoor**  \n",
    "2. **Überwachungskameras – Outdoor**  \n",
    "3. **Normale Fotos – Indoor** (Front-, Seiten-, Heckansicht)  \n",
    "4. **Normale Fotos – Outdoor** (Front-, Seiten-, Heckansicht)  \n",
    "5. **Komplexe Szenen** mit mehreren Hunden in einem Bild  \n",
    "6. **Interaktive Szenen** mit Hunden in Anwesenheit von Menschen  \n",
    "7. **Teilverdeckungen** durch Möbel, Decken oder andere Objekte (z. B. Sofa)  \n",
    " \n",
    "Diese Diversität soll sicherstellen, dass das Modell nicht nur typische Überwachungsbilder lernt, sondern auch alle Facetten der Hundeform in unterschiedlichsten Kontexteinflüssen erfasst.\n",
    " \n",
    "## 3. Zu untersuchende Einflussfaktoren  \n",
    "Wir analysieren systematisch, wie die folgenden Störgrössen die Lokalisierungsgenauigkeit beeinflussen:  \n",
    "- **Teilweise Verdeckung** (z. B. Hund unter einer Decke oder hinter Möbeln)  \n",
    "- **Mehrfachüberlappung** (z. B. zwei oder mehr Hunde in engem Kontakt)  \n",
    "- **Unruhiger Hintergrund** (komplexe Texturen oder visuelle Ablenkungen)  \n",
    "- **Beleuchtungsschwankungen** (Tag-/Nachtbetrieb, Schattenwurf, künstliche Lichtquellen)  \n",
    "- **Variable Bildqualität** (Auflösung, Kompressionsartefakte, Bildrauschen)  \n",
    "- **Anwesenheit von Menschen** als potenzielle Interaktions- oder Störfaktoren  \n",
    " \n",
    "Jeder dieser Faktoren wird in kontrollierten Testsets abgebildet, um ihren isolierten und kombinierten Einfluss auf die Performance zu bewerten.\n",
    " \n",
    "## 4. Forschungsfrage und Hypothese  \n",
    "**Forschungsfrage:**  \n",
    "> In welchem Ausmass kann ein auf Hunde spezialisiertes CNN Hunde in den genannten Indoor- und Outdoor-Szenarien zuverlässig lokalisieren und welche der beschriebenen Einflussfaktoren beeinträchtigen die Lokalisierungsgenauigkeit am stärksten?  \n",
    " \n",
    "**Hypothese:**  \n",
    "> Wir erwarten, dass insbesondere **teilweise Verdeckungen** (z. B. durch Möbel oder andere Hunde) und **Mehrfachüberlappungen** zu einer signifikanten Verschlechterung der Erkennungsleistung führen, während moderate Hintergrundkomplexität und Beleuchtungsschwankungen weniger kritische Einbussen bewirken."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c47ba26",
   "metadata": {},
   "source": [
    "## Aktuelle Datenlage\n",
    "\n",
    "Auf Basis der explorativen Analyse von vier Datensätzen mit unterschiedlichen Strukturen liegen folgende Kernergebnisse vor:\n",
    "\n",
    "### 1. Datensatz- und Bildübersicht\n",
    "- **Anzahl Datensätze:** 4 (Dataset 1–4)  \n",
    "- **Strukturen:**  \n",
    "  - Dataset 1: „annotations/images“  \n",
    "  - Dataset 2–4: „train/test/valid“ im VOC-Format  \n",
    "- **Einzigartige Bilder:** 5 299  \n",
    "- **Annotationen (XML-Dateien):** 5 304  \n",
    "\n",
    "### 2. Bounding-Box-Statistiken\n",
    "- **Gesamtanzahl Objekte:** 6 216 Bounding-Boxen  \n",
    "- **Mittlere Abmessungen (px):**  \n",
    "  - Breite 156 ± 109  \n",
    "  - Höhe 161 ± 110  \n",
    "  - Fläche ca. 34 971 ± 55 421  \n",
    "- **Verteilung (50%-Quartile):**  \n",
    "  - Breite 130 px  \n",
    "  - Höhe 134 px  \n",
    "  - Fläche 15 480 px²  \n",
    "- **Extremwerte:**  \n",
    "  - Breiteste Box: 640 px  \n",
    "  - Schmalste Box: 16 px  \n",
    "  - Max. Flächenanteil: 409 600 px²  \n",
    "  - Min. Flächenanteil: 496 px²  \n",
    "\n",
    "### 3. Klassenverteilung\n",
    "| Klasse    | Count | Anteil (%) |\n",
    "|-----------|------:|-----------:|\n",
    "| dog       | 3 416 |      54.96 |\n",
    "| bird      | 1 223 |      19.67 |\n",
    "| cat       | 1 190 |      19.14 |\n",
    "| Abrador   |   128 |       2.06 |\n",
    "| Shiba-Inu |   121 |       1.95 |\n",
    "| Chihuahua |   113 |       1.82 |\n",
    "| persons   |    16 |       0.26 |\n",
    "| car       |     9 |       0.14 |\n",
    "*Summe: 6 216 Objects*\n",
    "\n",
    "### 4. Bildauflösungen\n",
    "- **Breite (px):** 114 – 640 (M = 490 ± 126; Q1 = 375; Q3 = 640)  \n",
    "- **Höhe (px):** 108 – 640 (M = 457 ± 142; Q1 = 333; Q3 = 640)  \n",
    "- **Seitenverhältnis (w/h):** stark konzentriert um 1:1, Ausreißer bis 6.7  \n",
    "\n",
    "### 5. Genutzte Datensätze & Links\n",
    "- **Oxford-IIIT Pet Dataset** (Primärdatensatz): pixelgenaue Trimap-Annotationen, Kopf-ROI, Rassenlabels  \n",
    "  – Link: https://www.robots.ox.ac.uk/~vgg/data/pets/  \n",
    "- **Kaggle “Dog and Cat Detection”**: Indoor-/Outdoor-Mischung  \n",
    "  – Link: https://www.kaggle.com/datasets/andrewmvd/dog-and-cat-detection?resource=download  \n",
    "- **Roboflow Universe – Dogs OVDDC**: Überwachungskamera-Szenarien  \n",
    "  – Link: https://universe.roboflow.com/wu-yuxuan-ovddc/dogs-5ulz9  \n",
    "- **Roboflow Universe – AIVLE5-WORF0 ASDF-T4TSD**: komplexe Indoor-/Outdoor-Hintergründe  \n",
    "  – Link: https://universe.roboflow.com/aivle5-worf0/asdf-t4tsd  \n",
    "- **Roboflow Universe – Max-EVO5Q Dog UXSTE**: Hunde mit Mensch- und Möbelinteraktionen  \n",
    "  – Link: https://universe.roboflow.com/max-evo5q/dog-uxste/browse?queryText=&pageSize=50&startingIndex=0&browseQuery=true  \n",
    "\n",
    "---\n",
    "\n",
    "## Empfehlungen für das weitere Vorgehen\n",
    "\n",
    "1. **Fokussierung auf „dog“**  \n",
    "   Entfernen aller Nicht-Dog-Annotationen, um ein reines Hunde-Detektionsproblem zu erhalten.\n",
    "\n",
    "2. **Vereinheitlichung & Formatkonvertierung**  \n",
    "   - Gemeinsame `train/val/test`-Aufteilung  \n",
    "   - Konvertierung aller Annotationen in ein einheitliches Format (z. B. COCO JSON oder YOLO TXT)\n",
    "\n",
    "3. **Ausgleich der Klassen- und Objektgrößenverteilung**  \n",
    "   - (Under-/Over-)Sampling nach Bounding-Box-Flächenklassen\n",
    "\n",
    "4. **Bildnormalisierung & Augmentation**  \n",
    "   - Resize auf eine Standardgröße (z. B. 640 × 640 px)  \n",
    "   - Simulierte Occlusions und Beleuchtungsvariationen\n",
    "\n",
    "5. **Szenario-Metadaten markieren**  \n",
    "   Labeln nach Indoor/Outdoor, Einzelhund/Mehrfachhund und Anwesenheit von Menschen für Subset-Analysen\n",
    "\n",
    "6. **Challenge-Set für robuste Evaluation**  \n",
    "   Separates Testset mit harten Fällen (starke Verdeckung, Überlappung, komplexe Hintergründe) zur gezielten Prüfung unserer Hypothese.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
