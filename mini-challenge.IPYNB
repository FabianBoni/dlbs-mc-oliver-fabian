{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini Challenge DLBS Oliver - Fabian\n",
    "## Fragestellung\n",
    "Die zuverlässige Lokalisierung von Haustieren in Bildern ist eine zentrale Aufgabe in Anwendungen wie automatischer Bildorganisation, Überwachungssystemen oder tiermedizinischer Diagnostik. Trotz Fortschritten in Deep-Learning-basierten Objektdetektionsmethoden wie YOLO und Faster R-CNN bleibt die Erkennungsgenauigkeit stark abhängig von verschiedenen Faktoren. Ziel dieser Untersuchung ist es, die Zuverlässigkeit dieser Methoden spezifisch für die Lokalisierung von Haustieren zu evaluieren und dabei kritisch zu analysieren, welche Faktoren besonders signifikanten Einfluss auf die Erkennungsqualität haben. Insbesondere sollen Faktoren wie Überlappung mehrerer Tiere, teilweise Verdeckung einzelner Tiere, unterschiedliche Bildqualität sowie komplexe oder unruhige Hintergründe betrachtet werden. Unsere zentrale Forschungsfrage lautet: Wie zuverlässig können YOLO und Faster R-CNN Haustiere in verschiedenen realistischen Szenarien erkennen und lokalisieren, und welche dieser genannten Faktoren beeinträchtigen dabei die Erkennungsqualität am stärksten? Die Hypothese lautet, dass insbesondere Überlappungen und teilweise Verdeckungen zu einer deutlichen Verschlechterung der Erkennungsleistung führen.\n",
    "## Datenlage\n",
    "Die Datengrundlage dieser Untersuchung bildet das Oxford-IIIT Pet Dataset, welches speziell für die Evaluation von Methoden zur automatischen Erkennung und Lokalisierung von Haustieren erstellt wurde. Es umfasst insgesamt 37 Kategorien mit etwa 200 Bildern pro Kategorie, wodurch eine breite Vielfalt an Haustieren, insbesondere Hunden und Katzen unterschiedlicher Rassen, abgedeckt wird. Die Bilder zeichnen sich durch starke Variationen in Bezug auf Skalierung, Haltung der Tiere sowie Beleuchtungsverhältnisse aus. Jedes Bild verfügt über annotierte Ground-Truth-Daten, einschließlich der genauen Klassifizierung der Rasse, markierter Region-of-Interest (ROI) des Kopfes sowie pixelgenauer Trimap-Segmentierungen. Diese Annotationen ermöglichen detaillierte Analysen der Lokalisierungsgenauigkeit. Wie bereits im Datensatz integriert und am bereitgestellten Beispielbild ersichtlich, sind präzise Ground-Truth-Informationen direkt verfügbar, was die Untersuchung zur Bewertung der Erkennungsqualität und Einflussfaktoren erheblich unterstützt."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
